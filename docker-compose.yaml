version: '3.9'
services:
  # Mysql
  mysql:
    image: mysql:8.0
    container_name: mysql
    ports:
      - "3307:3306"
    environment:
      - MYSQL_DATABASE=${MYSQL_DATABASESS}
      - MYSQL_ROOT_USER=${MYSQL_ROOT_USER}
      - MYSQL_USER=${MYSQL_USER}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
    volumes:
      - mysql:/var/lib/mysql
      - ./load_data_into_mysql/stock_market.sql:/tmp/stock_market.sql
    networks:
      - de_network

  # Postgresql
  psql:
    image: postgres:14-alpine
    container_name: psql
    hostname: psql
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./pg_hba.conf:/tmp/pg_hba.conf
    command: ["postgres", "-c", "hba_file=/tmp/pg_hba.conf"]
    expose:
      - "5432"
    ports:
      - "5432:5432"
    env_file: .env
    networks:
      - de_network

  # Mariadb
  mariadb:
    hostname: mariadb
    image: mariadb:10.5.16
    ports:
      - 3309:3306
    env_file: .env
    volumes:
      - mariadb:/var/lib/mysql
    networks:
      - de_network
  
  # Hive metastore
  hive-metastore:
    hostname: hive-metastore
    image: 'bitsondatadev/hive-metastore:latest'
    ports:
      - '9083:9083' # Metastore Thrift
    volumes:
      - ./docker/data_lakehouse/conf/metastore-site.xml:/opt/apache-hive-metastore-3.0.0-bin/conf/metastore-site.xml:ro
    env_file: .env
    depends_on:
      - mariadb
    networks:
      - de_network

  # Minio
  minio:
    hostname: minio
    image: 'minio/minio:latest'
    container_name: minio
    ports:
      - '9001:9001'
      - '9000:9000'
    volumes:
      - minio:/data
    env_file: .env
    command: ["server", "/data", "--console-address", ":9001"]
    networks:
      - de_network

  # Minio Client
  mc:
    image: minio/mc
    container_name: mc
    hostname: mc
    env_file: .env
    # entrypoint: >
    #   /bin/sh -c " until (/usr/bin/mc config host add minio http://minio:9000 minio_username minio_password) do echo '...waiting...' && sleep 10; done; /usr/bin/mc mb minio/mlflow; /usr/bin/mc policy set public minio/mlflow; tail -f /dev/null;"
    entrypoint: >
        /bin/sh -c " until (/usr/bin/mc config host add minio http://minio:9000 minio_username minio_password) do echo '...waiting...' && sleep 10; done; tail -f /dev/null;"
    depends_on:
      - minio
    networks:
      - de_network

  # Trino
  trino:
    hostname: trino
    image: 'trinodb/trino:359'
    ports:
      - '8085:8080'
    volumes:
      - ./docker/data_lakehouse/etc:/etc/trino
    networks:
      - de_network
    depends_on:
      - minio
      - hive-metastore

  # Spark master, worker and notebook
  spark-master:
    build: 
      context: ./docker/spark_cluster
      dockerfile: Dockerfile
    container_name: "spark-master"
    env_file: 
      - spark-master.env
    ports:
      - "7077:7077"
      - "8080:8080"
    expose:
      - "7077"
    volumes:
      - ./docker/spark_cluster/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./docker/spark_cluster/conf/log4j.properties:/opt/bitnami/spark/conf/log4j.properties
    networks:
      - de_network

  spark-worker-1:
    image: docker.io/bitnami/spark:3.3.2
    container_name: "spark-worker-1"
    env_file: 
      - spark-worker.env
    networks:
      - de_network

  spark-notebook:
    build: 
      context: ./docker/notebooks
      dockerfile: Dockerfile
    container_name: "spark-notebook"
    user: root
    env_file: .env
    volumes:
      - ./docker/notebooks/work:/home/jovyan/work
      - ./docker/notebooks/conf/spark-defaults.conf:/usr/local/spark/conf/spark-defaults.conf
    ports:
      - "8888:8888"
      - "4040:4040"
    networks:
      - de_network

  # UI dashboard
  superset:
    build:
      context: ./docker/superset
      dockerfile: Dockerfile
    container_name: Superset
    env_file:
      - .env
    ports:
      - '8088:8088'
    volumes:
      - superset_home:/app/superset_home
    networks:
    - de_network

  # Streamlit
  # streamlit:
  #   build:
  #     context: ./docker/streamlit
  #     dockerfile: Dockerfile
  #   container_name: streamlit
  #   volumes:
  #     - ./app:/app
  #   env_file:
  #     - .env
  #   ports:
  #     - "8501:8501"
  #   networks:
  #     - de_network

  # UI mlflow
  # web:
  #   restart: always
  #   build: ./docker/mlflow
  #   image: mlflow_server
  #   container_name: mlflow_server
  #   depends_on:
  #     - mc
  #     - mysql
  #   ports:
  #     - "7893:5000"
  #   env_file:
  #     - .env
  #   command: mlflow server --backend-store-uri mysql+pymysql://${MYSQL_ROOT_USER}:${MYSQL_ROOT_PASSWORD}@mysql:3306/${MYSQL_DATABASESS} --default-artifact-root s3://mlflow/ --host 0.0.0.0
  #   networks:
  #     - de_network

  # Dagster
  dagster_dagit:
    build:
      context: ./docker/dagster
      dockerfile: Dockerfile
    entrypoint:
      - dagit
      - -h
      - "0.0.0.0"
      - -p
      - "3001"
      - -w
      - workspace.yaml
    container_name: dagster_dagit
    ports:
      - "3001:3001"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./dagster_home:/opt/dagster/dagster_home
    env_file:
      - .env
    networks:
      - de_network
    depends_on:
      - psql

  dagster_daemon:
    build:
      context: ./docker/dagster
      dockerfile: Dockerfile
    entrypoint:
      - dagster-daemon
      - run
    container_name: dagster_daemon
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./dagster_home:/opt/dagster/dagster_home
    env_file:
      - .env
    networks:
      - de_network
    depends_on:
      - psql

  etl_pipeline:
    build:
      context: ./etl_pipeline
      dockerfile: Dockerfile
    container_name: etl_pipeline
    user: root
    volumes:
      - ./etl_pipeline:/opt/dagster/app/etl_pipeline
      - ./etl_pipeline/spark-defaults.conf:/usr/local/spark/conf/spark-defaults.conf
    env_file:
      - .env
    expose:
      - "4000"
    networks:
      - de_network

volumes:
  minio: {}
  postgres_data: {}
  mysql: {}
  mariadb: {}
  superset_home: {}

networks:
  de_network:
    driver: bridge
    name: de_network